name: Scrape Rojadirecta Matches

on:
  schedule:
    # Run every 3 hours
    - cron: '0 */3 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      extract_nested:
        description: 'Extract nested iframes (slower but more complete)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
  
  # Run on push to main (optional, for testing)
  push:
    branches:
      - main
    paths:
      - 'scraper.py'
      - '.github/workflows/scrape.yml'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Cache Python packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-python.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-python.txt
      
      - name: Run scraper (without nested iframe extraction for speed)
        run: |
          echo "Starting scraper..."
          python scraper.py --no-nested
          echo "Scraper finished"
          
          # Check if file was created
          if [ -f "rojadirecta_matches.json" ]; then
            echo "âœ“ Output file created successfully"
            ls -lh rojadirecta_matches.json
            echo "File contents preview:"
            head -n 20 rojadirecta_matches.json
          else
            echo "âœ— ERROR: Output file not created!"
            exit 1
          fi
      
      - name: Validate JSON output
        run: |
          python -c "import json; data = json.load(open('rojadirecta_matches.json')); print(f'Valid JSON with {data[\"total_matches\"]} matches')"
      
      - name: Check if there are changes
        id: verify_diff
        run: |
          if [ ! -f "rojadirecta_matches.json" ]; then
            echo "File doesn't exist"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          git add -N rojadirecta_matches.json
          if git diff --quiet rojadirecta_matches.json; then
            echo "No changes detected"
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected"
            echo "changed=true" >> $GITHUB_OUTPUT
          fi
      
      - name: Show diff (if changed)
        if: steps.verify_diff.outputs.changed == 'true'
        run: |
          echo "Changes in matches data:"
          git diff rojadirecta_matches.json | head -n 50
      
      - name: Commit and push if changed
        if: steps.verify_diff.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add rojadirecta_matches.json
          
          # Get match count
          MATCH_COUNT=$(python -c "import json; print(json.load(open('rojadirecta_matches.json'))['total_matches'])")
          
          git commit -m "ðŸ”„ Update matches data - ${MATCH_COUNT} matches [$(date -u +'%Y-%m-%d %H:%M UTC')]"
          git push
      
      - name: Upload artifact (always)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rojadirecta-matches-${{ github.run_number }}
          path: |
            rojadirecta_matches.json
            *.log
          retention-days: 7
          if-no-files-found: warn
      
      - name: Create summary
        if: always()
        run: |
          echo "## Scraping Results ðŸŽ¯" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "rojadirecta_matches.json" ]; then
            MATCH_COUNT=$(python -c "import json; d=json.load(open('rojadirecta_matches.json')); print(d['total_matches'])")
            SCRAPE_TIME=$(python -c "import json; d=json.load(open('rojadirecta_matches.json')); print(d['scraped_at'])")
            
            echo "âœ… **Status:** Success" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“Š **Total Matches:** ${MATCH_COUNT}" >> $GITHUB_STEP_SUMMARY
            echo "â° **Scraped At:** ${SCRAPE_TIME}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            echo "### Match Preview" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            python -c "import json; d=json.load(open('rojadirecta_matches.json')); [print(f\"{i+1}. {m['time']} - {m['sport']} - {m['title']} ({len(m['streams'])} streams)\") for i, m in enumerate(d['matches'][:5])]"  >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Status:** Failed - No output file created" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Scraping failed! Check the logs for details."
